service:
  extensions: [ jaeger_storage, jaeger_query, remote_sampling, healthcheckv2 ]
  pipelines:
    traces:
      receivers: [ otlp, jaeger, zipkin ]  # nop
      processors: [ batch, adaptive_sampling ] # tail_sampling adaptive_sampling
      exporters: [ jaeger_storage_exporter,otlp ] # nop spanmetrics
    metrics/spanmetrics:
      receivers: [ nop ]
      exporters: [ prometheus ]
  telemetry:
    resource:
      service.name: jaeger
    metrics:
      level: detailed
      readers:
        - pull:
            exporter:
              prometheus:
                host: 0.0.0.0
                port: 8888
    logs:
      level: debug
    # TODO Initialize telemetry tracer once OTEL released new feature.
    # https://github.com/open-telemetry/opentelemetry-collector/issues/10663

extensions:
  healthcheckv2:
    endpoint: 0.0.0.0:13133
    use_v2: true
    http:
      # use different port to avoid conflict with collector on 13133
      endpoint: 0.0.0.0:12133
      config: 
        enabled: true
        path: /config
      status:
        enabled: true
        path: /status
    grpc:
      endpoint: "0.0.0.0:12132"

  # pprof:
  #   endpoint: 0.0.0.0:1777

  zpages:
    # for some reason the official extension listens on ephemeral port 55679
    # so we override it with a normal port
    endpoint: 0.0.0.0:27778

  expvar:
    endpoint: "0.0.0.0:27777"


  jaeger_query:
    storage:
      traces: some_store
      traces_archive: another_store
    ui:
      config_file: /cmd/jaeger/config-ui.json
      log_access: true
      assets_path: 
    # The maximum duration that is considered for clock skew adjustments.
    # Defaults to 0 seconds, which means it's disabled.
    max_clock_skew_adjust: 0s
    http:
      endpoint: 0.0.0.0:16686
    grpc: 
      endpoint: 0.0.0.0:16685
    base_path: /
    enable_tracing: true

  jaeger_storage:
    backends:
      some_store:
        # # memory
        # memory:
        #   max_traces: 100000
        # badger
        badger:
          directories:
            keys: "/cmd/jaeger/data/now/"
            values: "/cmd/jaeger/data/now/"
          ephemeral: false
        # cassandra
        # cassandra:
        #   schema:
        #     keyspace: "jaeger_v1_dc1"
        #     create: "${env:CASSANDRA_CREATE_SCHEMA:-true}"
        #   connection:
        #     auth:
        #       basic:
        #         username: "cassandra"
        #         password: "cassandra"
        #     tls:
        #       insecure: true
        # elasticsearch
        # elasticsearch:
        #   server_urls:
        #     - http://localhost:9200
        #   indices:
        #     index_prefix: "jaeger-main"
        #     spans:
        #       date_layout: "2006-01-02"
        #       rollover_frequency: "day"
        #       shards: 5
        #       replicas: 1
        #     services:
        #       date_layout: "2006-01-02"
        #       rollover_frequency: "day"
        #       shards: 5
        #       replicas: 1
        #     dependencies:
        #       date_layout: "2006-01-02"
        #       rollover_frequency: "day"
        #       shards: 5
        #       replicas: 1
        #     sampling:
        #       date_layout: "2006-01-02"
        #       rollover_frequency: "day"
        #       shards: 5
        #       replicas: 1
        # openSearch
        # opensearch:
        #   server_urls:
        #     - http://localhost:9200
        #   indices:
        #     index_prefix: "jaeger-main"
        #     spans:
        #       date_layout: "2006-01-02"
        #       rollover_frequency: "day"
        #       shards: 5
        #       replicas: 1
        #     services:
        #       date_layout: "2006-01-02"
        #       rollover_frequency: "day"
        #       shards: 5
        #       replicas: 1
        #     dependencies:
        #       date_layout: "2006-01-02"
        #       rollover_frequency: "day"
        #       shards: 5
        #       replicas: 1
        #     sampling:
        #       date_layout: "2006-01-02"
        #       rollover_frequency: "day"
        #       shards: 5
        #       replicas: 1
        # remote-storage
        # grpc:
        #   endpoint: localhost:17271
        #   tls:
        #     insecure: true
      another_store:
        # memory:
        #   max_traces: 100000
        badger:
          directories:
            keys: "/cmd/jaeger/data/archive/"
            values: "/cmd/jaeger/data/archive/"
          ephemeral: false
        # cassandra:
        #   schema:
        #     keyspace: "jaeger_v1_dc1_archive"
        #     create: "${env:CASSANDRA_CREATE_SCHEMA:-true}"
        #   connection:
        #     auth:
        #       basic:
        #         username: "cassandra"
        #         password: "cassandra"
        #     tls:
        #       insecure: true
        # elasticsearch:
        #   server_urls:
        #     - http://localhost:9200
        #   indices:
        #     index_prefix: "jaeger-archive"
        # opensearch:
        #   server_urls:
        #     - http://localhost:9200
        #   indices:
        #     index_prefix: "jaeger-archive"
        # grpc:
        #   endpoint: localhost:17272
        #   tls:
        #     insecure: true
    metric_backends:
      some_metrics_storage:
        prometheus:
          endpoint: http://prometheus:9090
          normalize_calls: true
          normalize_duration: true
  storage_cleaner:
    trace_storage: storage
    port: "9231"
    # /purge


  remote_sampling:
    # You can either use file or adaptive sampling strategy in remote_sampling
    # file:
    #   path: /cmd/jaeger/sampling-strategies.json
    #   default_sampling_probability: 0.1
    #   reload_interval: 60s
    adaptive:
      sampling_store: some_store
      initial_sampling_probability: 0.1
    http:
      endpoint: "0.0.0.0:5778"
    grpc:
      endpoint: "0.0.0.0:5779"

receivers:
  otlp:
    protocols:
      grpc:
        endpoint: "0.0.0.0:4317"
        #read_buffer_size: 
        transport: tcp
      http:
        endpoint: "0.0.0.0:4318"
        logs_url_path: /v1/logs
        traces_url_path: /v1/traces
        metrics_url_path: /v1/metrics

  # kafka ingester
  kafka:
    brokers:
      - localhost:9092
    topic: ${env:KAFKA_TOPIC:-jaeger-spans}
    encoding: ${env:KAFKA_ENCODING:-otlp_proto}
    initial_offset: earliest
    message_marking: 
      after: false
      on_error: false
    header_extraction:
      extract_headers: false

  nop:

  jaeger:
    protocols:
      grpc:
        endpoint: "0.0.0.0:14250"
      thrift_binary:
        endpoint: "0.0.0.0:6832"
      thrift_compact:
        endpoint: "0.0.0.0:6831"
      thrift_http:
        endpoint: "0.0.0.0:14268"

  zipkin:
    endpoint: "0.0.0.0:9411"
    parse_string_tags: false

processors:
  batch:
    send_batch_size: 8192
    #send_batch_max_size:
    #timeout: 
    metadata_cardinality_limit: 1000
  
  # memory_limiter:
  #   min_gc_interval_when_soft_limited: 10s


  #attributes:

    
  # Adaptive Sampling Processor is required to support adaptive sampling.
  # It expects remote_sampling extension with `adaptive:` config to be enabled.
  adaptive_sampling:

  # tail sampling always
  tail_sampling:
    decision_wait: 5s
    num_traces: 5000
    policies: [ { name: test-policy-1, type: always_sample } ]
  # tail sampling service
  # tail_sampling:
  #   decision_wait: 5s
  #   policies:
  #     [
  #       {
  #         name: filter-by-attribute,
  #         type: string_attribute,
  #         string_attribute:
  #           { key: service.name, values: [ tracegen-00, tracegen-03 ] },
  #       },
  #     ]

exporters:
  debug: 
    verbosity: 0
    sampling_initial: 2
    sampling_thereafter:  1
    use_internal_logger: true

  otlp:
    endpoint: "127.0.0.1:4317"
    tls:
      insecure: true
      # ca_file: ca.pem
      # cert_file: cert.pem
      # key_file: key.pem
    headers:
      test1: "value1"
      "test 2": "value 2"
    balancer_name: "round_robin"
    compression: gzip
    write_buffer_size: 524288
    keepalive: 
    timeout: 5s
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      randomization_factor: 0.5
      multiplier: 1.5
      max_interval: 30s
      max_elapsed_time: 5m
    sending_queue:
      enabled: true
      wait_for_result:
      sizer: "requests"
      queue_size: 1000
      block_on_overflow: false
      # blocking: 
      storage:
      num_consumers: 10
      batch: 
  
  otlp/2:
    endpoint: "127.0.0.1:4317"
    tls:
      insecure: true
      ca_file: ca.pem
      cert_file: cert.pem
      key_file: key.pem
    headers:
      test1: "value1"
      "test 2": "value 2"
    balancer_name: "round_robin"
    compression: gzip
    write_buffer_size: 524288
    keepalive: 
    timeout: 5s
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      randomization_factor: 0.5
      multiplier: 1.5
      max_interval: 30s
      max_elapsed_time: 5m
    sending_queue:
      enabled: true
      wait_for_result:
      sizer: "requests"
      queue_size: 1000
      block_on_overflow: false
      # blocking: 
      storage:
      num_consumers: 10
      batch: 

  otlphttp:
    # proto json
    encoding: proto
    traces_endpoint: http://127.0.0.1:4318/v1/traces
    metrics_endpoint: http://127.0.0.1:4318/v1/metrics
    logs_endpoint: http://127.0.0.1:4318/v1/logs
    endpoint: http://127.0.0.1:4318
    timeout: 30s
    compression: gzip
    write_buffer_size: 524288
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      randomization_factor: 0.5
      multiplier: 1.5
      max_interval: 30s
      max_elapsed_time: 5m
    sending_queue:
      enabled: true
      wait_for_result:
      sizer: "requests"
      queue_size: 1000
      block_on_overflow: false
      # blocking: 
      storage:
      num_consumers: 10
      batch:

  jaeger_storage_exporter:
    trace_storage: some_store

  # kafka collector
  kafka:
    brokers:
      - localhost:9092
    #producer:
    #retry_on_failure: 
    topic: ${env:KAFKA_TOPIC:-jaeger-spans}
    encoding: ${env:KAFKA_ENCODING:-otlp_proto}
    partition_metrics_by_resource_attributes: false
    partition_logs_by_resource_attributes: false

  nop:
  prometheus:
    endpoint: "0.0.0.0:8889"
    send_timestamps: false
    metric_expiration: 5m
    enable_open_metrics: false
    add_metric_suffixes: true

connectors:
  forward:
  #spanmetrics:
    
